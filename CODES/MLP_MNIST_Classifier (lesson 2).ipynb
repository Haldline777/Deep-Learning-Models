{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc4ead3",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ”¢ Multi-Layer Perceptron (MLP) for Handwritten Digit Classification\n",
    "\n",
    "This notebook demonstrates how to build a Multi-Layer Perceptron (MLP) using TensorFlow/Keras to classify handwritten digits from the MNIST dataset. It includes steps for data preprocessing, model creation, training, and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7829a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6760fba",
   "metadata": {},
   "source": [
    "\n",
    "We import necessary modules from TensorFlow to build and train the MLP model. The MNIST dataset is included in Keras for easy access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f361d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97809cb2",
   "metadata": {},
   "source": [
    "\n",
    "The dataset contains 28x28 grayscale images of handwritten digits. Normalizing pixel values helps improve training performance and stability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ffc79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define MLP model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),         # Converts 28x28 images to 784 input neurons\n",
    "    Dense(128, activation='relu'),         # First hidden layer\n",
    "    Dense(64, activation='relu'),          # Second hidden layer\n",
    "    Dense(10, activation='softmax')        # Output layer for 10 classes (0-9)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbc804",
   "metadata": {},
   "source": [
    "\n",
    "We use a simple MLP with two hidden layers:\n",
    "- `Flatten` reshapes the input image.\n",
    "- `Dense` layers with ReLU activation learn complex patterns.\n",
    "- `Softmax` outputs class probabilities for 10 digits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3df566",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e78e40e",
   "metadata": {},
   "source": [
    "\n",
    "We compile the model with the Adam optimizer and sparse categorical crossentropy for multi-class classification. The model is trained for 10 epochs with validation on the test set.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}